# Sp√©cification technique ‚Äî Module de matching LLM

## Document de r√©f√©rence pour l'impl√©mentation

**Projet** : AJT PRO
**Module** : Rapprochement produits fournisseurs par extraction LLM
**Date** : 11/02/2026
**Statut** : Valid√© ‚Äî pr√™t pour impl√©mentation

---

## 1. D√©cisions act√©es

| Sujet | D√©cision |
|-------|----------|
| D√©clenchement du matching | **Sur demande** via bouton dans l'UI (pas dans le pipeline ETL auto) |
| Produits sans correspondance | **Cr√©ation automatique si score < 50**, validation manuelle entre 50-89 |
| Variantes r√©gionales | **Produits distincts** dans le r√©f√©rentiel (EU ‚â† US Spec ‚â† Indian Spec) |
| Mod√®le LLM | Claude Haiku 4.5 (`claude-haiku-4-5-20251001`) via API Anthropic |
| Seuils de matching | ‚â• 90 auto / 50-89 validation / < 50 cr√©ation produit |
| Doublons prix/quantit√© | Un seul appel LLM par libell√© unique, r√©sultat en cache pour les doublons |
| Seuils configurables | Hardcod√©s pour la V1, configurable via UI pr√©vu en V2 |

---

## 2. Pr√©requis

### 2.1 Compte API Anthropic

- Cr√©er un compte sur [console.anthropic.com](https://console.anthropic.com)
- G√©n√©rer une cl√© API
- Charger 5‚Ç¨ de cr√©dits pr√©pay√©s
- Ajouter dans `.env` :

```bash
ANTHROPIC_API_KEY=sk-ant-xxxxx
LLM_MODEL=claude-haiku-4-5-20251001
LLM_BATCH_SIZE=25
MATCH_THRESHOLD_AUTO=90
MATCH_THRESHOLD_REVIEW=50
```

### 2.2 D√©pendance Python

```bash
# Ajouter dans requirements.txt
anthropic>=0.40.0
```

---

## 3. Modifications du mod√®le de donn√©es

### 3.1 Migration : colonne `region` sur `products`

```python
# alembic/versions/xxxx_add_region_to_products.py

def upgrade():
    op.add_column('products', sa.Column('region', sa.String(30), nullable=True))
    op.add_column('temporary_imports', sa.Column('region', sa.String(30), nullable=True))

def downgrade():
    op.drop_column('products', 'region')
    op.drop_column('temporary_imports', 'region')
```

Valeurs attendues : `null` (EU par d√©faut), `"US"`, `"IN"`, `"DE"`, etc.

Impact mod√®le SQLAlchemy (`models.py`) :
```python
class Product(db.Model):
    # ... colonnes existantes ...
    region = db.Column(db.String(30), nullable=True)  # NOUVEAU

class TemporaryImport(db.Model):
    # ... colonnes existantes ...
    region = db.Column(db.String(30), nullable=True)  # NOUVEAU
```

### 3.2 Nouvelle table : `model_references`

Table de correspondance codes constructeur ‚Üí nom commercial.

```python
class ModelReference(db.Model):
    __tablename__ = "model_references"

    id = db.Column(db.Integer, primary_key=True)
    manufacturer_code = db.Column(db.String(50), nullable=False, unique=True)
    commercial_name = db.Column(db.String(100), nullable=False)
    brand_id = db.Column(db.Integer, db.ForeignKey("brands.id"), nullable=True)
    brand = db.relationship("Brand", backref=db.backref("model_references", lazy=True))
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
```

Donn√©es initiales (script d'insertion ou migration) :

```
SM-S938B / S938B  ‚Üí  Galaxy S25 Ultra     (Samsung)
SM-S936B / S936B  ‚Üí  Galaxy S25+          (Samsung)
SM-S931B / S931B  ‚Üí  Galaxy S25           (Samsung)
SM-S928B / S928B  ‚Üí  Galaxy S24 Ultra     (Samsung)
SM-S926B / S926B  ‚Üí  Galaxy S24+          (Samsung)
SM-S921B / S921B  ‚Üí  Galaxy S24           (Samsung)
SM-A566B / A566B  ‚Üí  Galaxy A56           (Samsung)
SM-A556B / A556B  ‚Üí  Galaxy A55           (Samsung)
SM-A546B / A546B  ‚Üí  Galaxy A54           (Samsung)
SM-A356B / A356B  ‚Üí  Galaxy A35           (Samsung)
SM-A166B / A166B  ‚Üí  Galaxy A16           (Samsung)
SM-X230N / X230N  ‚Üí  Galaxy Tab A11+      (Samsung)
```

### 3.3 Nouvelle table : `label_cache`

Cache des r√©sultats de matching LLM pour √©viter les appels redondants.

```python
class LabelCache(db.Model):
    __tablename__ = "label_cache"

    id = db.Column(db.Integer, primary_key=True)
    supplier_id = db.Column(db.Integer, db.ForeignKey("suppliers.id"), nullable=False)
    supplier = db.relationship("Supplier", backref=db.backref("label_cache", lazy=True))
    normalized_label = db.Column(db.String(300), nullable=False)
    product_id = db.Column(db.Integer, db.ForeignKey("products.id"), nullable=True)
    product = db.relationship("Product", backref=db.backref("label_cache", lazy=True))
    match_score = db.Column(db.Integer, nullable=True)
    match_source = db.Column(db.String(20), nullable=False)  # 'auto', 'manual', 'llm'
    extracted_attributes = db.Column(db.JSON, nullable=True)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    last_used_at = db.Column(db.DateTime, default=datetime.utcnow)

    __table_args__ = (
        db.UniqueConstraint('supplier_id', 'normalized_label', name='uix_label_cache'),
    )
```

### 3.4 Nouvelle table : `pending_matches`

File d'attente pour les matchs en attente de validation (score 50-89).

```python
class PendingMatch(db.Model):
    __tablename__ = "pending_matches"

    id = db.Column(db.Integer, primary_key=True)
    supplier_id = db.Column(db.Integer, db.ForeignKey("suppliers.id"), nullable=False)
    supplier = db.relationship("Supplier")
    temporary_import_id = db.Column(db.Integer, db.ForeignKey("temporary_imports.id"), nullable=True)
    source_label = db.Column(db.String(300), nullable=False)
    extracted_attributes = db.Column(db.JSON, nullable=False)
    candidates = db.Column(db.JSON, nullable=False)  # [{product_id, score, details}]
    status = db.Column(db.String(20), default='pending')  # 'pending', 'validated', 'rejected', 'created'
    resolved_product_id = db.Column(db.Integer, db.ForeignKey("products.id"), nullable=True)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    resolved_at = db.Column(db.DateTime, nullable=True)
```

### 3.5 Enrichissement `color_translations`

Couleurs √† ajouter d'apr√®s l'analyse des donn√©es Yukatel et PlusPos :

| color_source | color_target_id (couleur cible) |
|-------------|-------------------------------|
| Midnight | ‚Üí Noir |
| Starlight | ‚Üí Blanc |
| Space Black | ‚Üí Noir |
| Space Grey | ‚Üí Gris |
| Space Gray | ‚Üí Gris |
| Graphite | ‚Üí Gris |
| Cloud White | ‚Üí Blanc |
| Mist Blue | ‚Üí Bleu |
| Sky Blue | ‚Üí Bleu |
| Deep Blue | ‚Üí Bleu |
| Cosmic Orange | ‚Üí Orange |
| Desert Titanium | ‚Üí Titane D√©sert * |
| Natural Titanium | ‚Üí Titane Naturel * |
| Black Titanium | ‚Üí Titane Noir * |
| White Titanium | ‚Üí Titane Blanc * |
| Deep Purple | ‚Üí Violet |
| Jetblack | ‚Üí Noir |
| Jet Black | ‚Üí Noir |
| Light Gold | ‚Üí Or |
| Lavender | ‚Üí Lavande * |
| Sage | ‚Üí Vert |
| Obsidian | ‚Üí Noir |
| Moonstone | ‚Üí Bleu |
| Charcoal | ‚Üí Gris |

\* Ces couleurs n'existent peut-√™tre pas encore dans la table `colors` ‚Üí √† cr√©er.

---

## 4. Backend ‚Äî Module LLM matching

### 4.1 Architecture fichiers

```
backend/
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ llm_matching.py          # NOUVEAU ‚Äî logique compl√®te du matching
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îî‚îÄ‚îÄ matching.py              # NOUVEAU ‚Äî endpoints API
‚îú‚îÄ‚îÄ models.py                    # Modifi√© ‚Äî nouvelles tables + colonne region
```

### 4.2 `backend/utils/llm_matching.py`

#### Fonction 1 : `normalize_label(label: str) -> str`

Normalise un libell√© pour servir de cl√© de cache.

```python
def normalize_label(label: str) -> str:
    """
    Supprime les espaces multiples, met en minuscule,
    retire les caract√®res sp√©ciaux inutiles.
    'Apple iPhone 15 128GB - Black' ‚Üí 'apple iphone 15 128gb black'
    """
```

#### Fonction 2 : `build_extraction_prompt(labels: list[str], context: dict) -> str`

Construit le prompt syst√®me avec injection dynamique des valeurs de r√©f√©rence.

```python
def build_extraction_prompt(labels: list[str], context: dict) -> str:
    """
    context contient :
    - brands: list[str] depuis Brand.query.all()
    - colors: dict[str, list[str]] depuis Color + ColorTranslation
    - storage_options: list[str] depuis MemoryOption.query.all()
    - model_references: dict[str, str] depuis ModelReference.query.all()
    - device_types: list[str] depuis DeviceType.query.all()
    """
```

**Prompt syst√®me :**

```
Tu es un expert en identification de produits √©lectroniques (smartphones,
tablettes, accessoires, audio). √Ä partir de chaque libell√© fournisseur,
extrais les attributs structur√©s.

MARQUES CONNUES : {brands}

COULEURS CONNUES (nom fran√ßais ‚Üí synonymes accept√©s) :
{colors_with_all_synonyms}

STOCKAGES CONNUS : {storage_options}

CORRESPONDANCES CODES CONSTRUCTEUR :
{model_references}

TYPES D'APPAREILS : {device_types}

R√àGLES D'EXTRACTION :
1. brand : identifie la marque parmi les marques connues
2. model_family : le nom commercial du mod√®le SANS la marque, le stockage
   ni la couleur. Ex: "iPhone 15 Pro Max", "Galaxy S25 Ultra", "AirPods 4 ANC"
   - Si un code constructeur Samsung est pr√©sent (S938B, A566B...),
     utilise la table de correspondance
3. storage : capacit√© de stockage en "Go" (128GB ‚Üí "128 Go"). null si absent
4. color : normalise en fran√ßais en utilisant les synonymes fournis.
   Si la couleur n'est dans aucun synonyme, garde le nom original
5. device_type : Smartphone, Tablette, Accessoire, Audio, etc.
6. region : null si standard EU. "US" si US Spec, "IN" si Indian Spec,
   "DE" si (DE), etc.
7. connectivity : "WiFi" si [W], "Cellular" si mention cellular/LTE,
   "5G" si mentionn√©, null sinon
8. grade : A, B, C si mentionn√©, null sinon
9. confidence : score entre 0.0 et 1.0

R√©ponds UNIQUEMENT avec un JSON array, sans markdown ni texte autour.
Un objet par libell√©, dans le m√™me ordre que les entr√©es.
```

**Message utilisateur :**

```
Extrais les attributs de ces {n} libell√©s :
1. {label_1}
2. {label_2}
...
```

#### Fonction 3 : `call_llm_extraction(labels: list[str], context: dict) -> list[dict]`

Appel API Claude et parsing de la r√©ponse.

```python
import anthropic

def call_llm_extraction(labels: list[str], context: dict) -> list[dict]:
    """
    Envoie un batch de libell√©s √† Claude Haiku.
    Retourne une liste de dicts avec les attributs extraits.
    
    Gestion d'erreurs :
    - Retry 2x en cas de timeout ou erreur 5xx
    - Si le JSON est invalide, retente avec un batch plus petit
    - Log chaque appel (nombre de tokens in/out, dur√©e, co√ªt)
    """
    client = anthropic.Anthropic()  # utilise ANTHROPIC_API_KEY depuis env
    
    prompt = build_extraction_prompt(labels, context)
    
    response = client.messages.create(
        model=os.getenv("LLM_MODEL", "claude-haiku-4-5-20251001"),
        max_tokens=4096,
        system=prompt,
        messages=[{
            "role": "user",
            "content": f"Extrais les attributs de ces {len(labels)} libell√©s :\n"
                       + "\n".join(f"{i+1}. {l}" for i, l in enumerate(labels))
        }]
    )
    
    return json.loads(response.content[0].text)
```

#### Fonction 4 : `score_match(extracted: dict, product: Product) -> int`

Calcule un score de correspondance entre les attributs extraits et un produit du r√©f√©rentiel.

```python
def score_match(extracted: dict, product: Product, mappings: dict) -> int:
    """
    Score sur 100.
    
    Pond√©ration :
    - brand:        15 pts (match exact insensible casse, sinon 0 et arr√™t)
    - model_family: 40 pts (exact=40, fuzzy Levenshtein‚â§3 = 20-30, sinon 0)
    - storage:      25 pts (match exact obligatoire, sinon disqualifiant)
    - color:        15 pts (exact ou via color_translations=15, sinon -5)
    - region:        5 pts (match exact, null==null=5)
    
    Si brand ou storage ne matchent pas ‚Üí retourne 0 directement.
    """
```

#### Fonction 5 : `find_best_matches(extracted: dict, products: list, top_n=3) -> list`

Trouve les meilleurs candidats dans le r√©f√©rentiel.

```python
def find_best_matches(extracted: dict, products: list, mappings: dict, top_n=3):
    """
    Retourne les top_n meilleurs matchs tri√©s par score d√©croissant.
    
    Optimisation : pr√©-filtre sur brand_id avant le scoring complet
    pour √©viter de scorer tous les produits.
    
    Retour : [{"product_id": int, "score": int, "product_name": str, "details": dict}]
    """
```

#### Fonction 6 : `create_product_from_extraction(extracted: dict) -> Product`

Cr√©e un nouveau produit dans le r√©f√©rentiel √† partir des attributs LLM.

```python
def create_product_from_extraction(extracted: dict) -> Product:
    """
    Cr√©e un Product avec :
    - model = extracted["model_family"]
    - description = label fournisseur original
    - brand_id = lookup Brand par nom
    - memory_id = lookup MemoryOption par stockage
    - color_id = lookup Color par nom (+ color_translations)
    - type_id = lookup DeviceType par type
    - region = extracted["region"]
    
    Si une couleur/m√©moire/marque n'existe pas ‚Üí la cr√©er dans la table de ref.
    
    Flag : le champ description contient "[AUTO]" en pr√©fixe pour rep√©rage.
    """
```

#### Fonction 7 : `run_matching_job(supplier_id: int | None = None) -> dict`

Orchestre tout le processus de matching.

```python
def run_matching_job(supplier_id: int | None = None) -> dict:
    """
    Flux principal :
    
    1. Charger les temporary_imports (filtr√©s par supplier_id si fourni)
    2. D√©dupliquer les libell√©s uniques
    3. Pour chaque libell√© unique :
       a. V√©rifier le label_cache ‚Üí si trouv√©, utiliser le r√©sultat cach√©
       b. Sinon, ajouter au batch LLM
    4. Envoyer les batchs au LLM (par lots de 25)
    5. Pour chaque r√©sultat d'extraction :
       a. Scorer contre le r√©f√©rentiel products
       b. Score ‚â• 90 ‚Üí cr√©er supplier_product_ref + alimenter label_cache
       c. Score 50-89 ‚Üí cr√©er pending_match
       d. Score < 50 ‚Üí cr√©er le produit + supplier_product_ref + label_cache
    6. Retourner le rapport :
       {
         "total_labels": int,
         "from_cache": int,
         "llm_calls": int,
         "auto_matched": int,
         "pending_review": int,
         "auto_created": int,
         "errors": int,
         "cost_estimate": float,
         "duration_seconds": float
       }
    """
```

### 4.3 `backend/routes/matching.py`

```python
bp = Blueprint("matching", __name__)

@bp.route("/matching/run", methods=["POST"])
@token_required("admin")
def run_matching():
    """
    Lance le matching LLM sur les temporary_imports.
    Body optionnel : {"supplier_id": int}
    Retourne le rapport de matching.
    """

@bp.route("/matching/pending", methods=["GET"])
@token_required("admin")
def list_pending():
    """
    Liste les matchs en attente de validation.
    Query params : supplier_id, page, per_page
    Retourne : [{id, source_label, extracted_attributes, candidates, created_at}]
    """

@bp.route("/matching/validate", methods=["POST"])
@token_required("admin")
def validate_match():
    """
    Valide un match propos√©.
    Body : {"pending_match_id": int, "product_id": int}
    Actions :
    - Met √† jour pending_match.status = 'validated'
    - Cr√©e le supplier_product_ref
    - Alimente le label_cache (source: 'manual')
    - Enrichit color_translations si couleur corrig√©e
    """

@bp.route("/matching/reject", methods=["POST"])
@token_required("admin")
def reject_match():
    """
    Rejette un match et optionnellement cr√©e un nouveau produit.
    Body : {"pending_match_id": int, "create_product": bool}
    """

@bp.route("/matching/stats", methods=["GET"])
@token_required("admin")
def matching_stats():
    """
    Statistiques globales du matching.
    Retourne : {
      total_cached, total_pending, total_auto_matched,
      total_auto_created, cache_hit_rate,
      by_supplier: [{name, cached, pending, matched, created}]
    }
    """

@bp.route("/matching/cache", methods=["GET"])
@token_required("admin")
def list_cache():
    """
    Consultation du cache de labels.
    Permet de voir et purger des entr√©es si besoin.
    """

@bp.route("/matching/cache/<int:cache_id>", methods=["DELETE"])
@token_required("admin")
def delete_cache_entry(cache_id):
    """Supprime une entr√©e du cache (force un re-matching au prochain run)."""
```

### 4.4 Enregistrement du blueprint

Dans `app.py`, ajouter :

```python
from routes.matching import bp as matching_bp
app.register_blueprint(matching_bp)
```

---

## 5. Frontend

### 5.1 Bouton de d√©clenchement

Sur `DataImportPage.tsx`, dans le panel de synchronisation, ajouter un bouton :

```
[üîó Lancer le rapprochement]  (par fournisseur ou global)
```

Au clic :
- Appel `POST /matching/run` (avec ou sans `supplier_id`)
- Affichage d'un spinner + barre de progression si possible
- √Ä la fin, notification avec le r√©sum√© :
  "342 match√©s automatiquement, 8 en attente de validation, 15 nouveaux produits cr√©√©s"

### 5.2 Page de validation (`MatchingValidationPage.tsx`)

Nouvelle page accessible depuis la navigation (ou onglet dans DataImportPage).

**√âl√©ments :**
- Badge dans la navigation avec le nombre de matchs en attente
- Liste filtrable par fournisseur
- Pour chaque pending_match :
  - Le libell√© fournisseur original
  - Les attributs extraits par le LLM (brand, model, storage, color, region)
  - Les candidats propos√©s avec leur score
  - Boutons : Valider / Voir alternatives / Cr√©er produit / Ignorer
- Actions en masse : valider tout au-dessus d'un certain score

### 5.3 Widget statistiques

Dans le dashboard existant, un petit widget :
- Taux de cache hit (%)
- Nombre de matchs en attente
- R√©partition auto / manual / cr√©√© par semaine

---

## 6. Flux complet ‚Äî Sc√©nario type

```
1. L'admin lance la sync Yukatel (pipeline ETL existant)
   ‚Üí 3000 lignes dans temporary_imports
   ‚Üí Rapport : "2100 match√©s par EAN, 900 sans correspondance"

2. L'admin clique sur [üîó Lancer le rapprochement]
   ‚Üí Le module LLM traite les 900 libell√©s non match√©s
   ‚Üí 700 en cache (d√©j√† vus lors d'une pr√©c√©dente sync) ‚Üí match instantan√©
   ‚Üí 200 nouveaux ‚Üí 8 appels LLM (batchs de 25)
   ‚Üí R√©sultat :
     - 150 match√©s automatiquement (score ‚â• 90)
     - 30 en attente de validation (score 50-89)
     - 20 nouveaux produits cr√©√©s (score < 50)

3. L'admin va sur la page de validation
   ‚Üí Valide 25 matchs, corrige 3, rejette 2
   ‚Üí Les 25 valid√©s alimentent le cache

4. Prochaine sync : les 25 labels corrig√©s sont en cache
   ‚Üí Encore moins d'appels LLM n√©cessaires
```

---

## 7. Planning d'impl√©mentation

| Jour | T√¢ches | Livrable |
|------|--------|----------|
| **J1** | Migration Alembic (region, model_references, label_cache, pending_matches) + mod√®les SQLAlchemy + seed color_translations + seed model_references | Base de donn√©es pr√™te |
| **J2** | `llm_matching.py` : fonctions 1-3 (normalize, prompt, appel LLM) + tests unitaires avec libell√©s r√©els | Extraction LLM fonctionnelle en CLI |
| **J3** | `llm_matching.py` : fonctions 4-6 (scoring, matching, cr√©ation produit) | Matching complet en CLI |
| **J4** | `llm_matching.py` : fonction 7 (orchestration) + `routes/matching.py` (tous les endpoints) | API REST compl√®te |
| **J5** | Test end-to-end avec donn√©es Yukatel + PlusPos r√©elles, calibrage des seuils | Rapport de performance |
| **J6** | Frontend : bouton de d√©clenchement + page de validation | UI fonctionnelle |
| **J7** | Frontend : widget stats + polish + tests + d√©ploiement | Production |

---

## 8. M√©triques de succ√®s

| M√©trique | Cible V1 | Cible apr√®s 1 mois |
|----------|----------|---------------------|
| Taux de match automatique (score ‚â• 90) | > 70% | > 90% |
| Taux de cache hit (2√®me sync+) | > 60% | > 95% |
| Temps de matching pour 3000 produits | < 5 min | < 30 sec (gr√¢ce au cache) |
| Co√ªt LLM par sync | < 0.30‚Ç¨ | < 0.05‚Ç¨ |
| Faux positifs (match auto incorrect) | < 5% | < 2% |